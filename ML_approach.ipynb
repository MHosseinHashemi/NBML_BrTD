{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0596b132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import warnings\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from pycaret.classification import *\n",
    "from torchvision.models import resnet152\n",
    "from torchvision.transforms import transforms\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f84cf49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# img_read = cv2.imread('C:\\\\Users\\\\Eurus\\\\Desktop\\\\YoloV8\\\\train\\\\images\\\\T_1321.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "# sns.heatmap(np.array(img_read), cmap='hot', annot=True, cbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5db3fe6",
   "metadata": {},
   "source": [
    "Here is what is gonna happen:\n",
    " - iterate over all pictures\n",
    " - read them all as GrayScale Images\n",
    " - extract images features\n",
    " - save them inside of a list\n",
    " - feed it into a transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db80e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Deep_features = []\n",
    "root = 'C:\\\\Users\\\\Eurus\\\\Desktop\\\\Data'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "# Load the ResNet-152 model\n",
    "resnet = resnet152(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbbe440",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (23): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (24): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (25): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (26): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (27): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (28): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (29): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (30): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (31): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (32): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (33): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (34): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (35): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.to(device)\n",
    "resnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d52ad3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation for preprocessing\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((540, 540)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1158b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(root):\n",
    "    # Iterate over the images\n",
    "    for idx in tqdm(os.listdir(root)):\n",
    "        \n",
    "        # Read the image\n",
    "        path = os.path.join(root, idx)\n",
    "        img = Image.open(path)\n",
    "        \n",
    "        # Preprocess and Normalize the images\n",
    "        img_tensor = preprocess(img).div(255.0).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Extract features using ResNet-152\n",
    "        with torch.no_grad():\n",
    "            features = resnet(img_tensor)\n",
    "            \n",
    "        # Flatten the features\n",
    "        features = features.flatten().cpu().numpy()\n",
    "        \n",
    "        # Store the features in the dictionary\n",
    "        if \"T\" in idx:\n",
    "            Deep_features.append({'Label':'T','Features':features})\n",
    "        elif \"N\" in idx:\n",
    "            Deep_features.append({'Label':'N','Features':features})\n",
    "        else:\n",
    "            print(\"error!\")\n",
    "            \n",
    "    \n",
    "    return Deep_features\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01c2503b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 13832/13832 [19:46<00:00, 11.66it/s]\n"
     ]
    }
   ],
   "source": [
    "Train_features = feature_extractor(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8032bbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data\n",
    "random.shuffle(Train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70ea2b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13832"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "977be84d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Label': 'N',\n",
       " 'Features': array([-1.06906367e+04, -2.52137656e+04,  2.92583965e+04,  2.28539238e+04,\n",
       "        -2.23684102e+04, -1.16935771e+04,  8.50717480e+03, -2.72449390e+03,\n",
       "        -3.79249492e+04,  1.15733555e+04,  1.24553311e+04,  2.67641699e+04,\n",
       "        -3.44325122e+03, -3.34180933e+03, -2.67707422e+04, -6.16123340e+03,\n",
       "        -1.09487012e+03, -1.48649316e+04,  4.16235693e+03,  9.56235547e+03,\n",
       "        -1.49115049e+04, -3.16527559e+04,  5.23125859e+04, -5.31482324e+03,\n",
       "        -5.17468994e+03,  1.22583813e+03,  7.54630518e+03,  1.60013994e+04,\n",
       "         2.62790488e+04,  1.15739170e+04,  5.44310840e+03, -1.82375410e+04,\n",
       "        -1.27712334e+04,  4.91903594e+04, -7.69909961e+03,  3.43182617e+03,\n",
       "        -5.56962793e+03, -1.69605469e+04,  2.17618984e+04,  1.81115000e+04,\n",
       "         2.15427500e+04,  7.81693457e+03,  1.00527949e+04, -2.11916387e+04,\n",
       "        -2.12089417e+02,  2.19853223e+04, -3.58642920e+03, -1.50200801e+04,\n",
       "         1.91814980e+04,  6.05122021e+03,  3.50683398e+04, -5.71064160e+03,\n",
       "         6.11986230e+03,  8.87293066e+03,  1.48658887e+04, -1.83007559e+04,\n",
       "        -3.53157656e+04, -1.55014424e+04,  2.03496753e+03, -2.62778008e+04,\n",
       "        -1.94307012e+04, -7.28751660e+03,  1.79428164e+04, -1.86549062e+04,\n",
       "         1.01266504e+04, -5.53892041e+03,  1.40030586e+04, -2.46990020e+04,\n",
       "         1.72280625e+04,  1.58624746e+04,  1.97736113e+04, -2.02165588e+02,\n",
       "        -1.08042295e+04,  4.05704199e+03, -2.32411445e+04, -1.06873379e+04,\n",
       "        -5.12177686e+03, -4.19726133e+04,  1.15305850e+04, -2.54838496e+04,\n",
       "         1.08205439e+04, -1.57556250e+04,  1.92524277e+04, -6.75114990e+03,\n",
       "         1.55401094e+04, -2.79910703e+04, -5.54966614e+02, -7.75027197e+03,\n",
       "        -4.06879102e+04,  2.44545215e+03,  1.78857500e+04, -1.14325195e+03,\n",
       "         3.06383789e+03,  3.05171814e+02, -1.48873018e+04,  2.68844355e+04,\n",
       "        -1.06385225e+04, -1.28784678e+04,  1.57845938e+04, -9.73353711e+03,\n",
       "        -1.64771484e+04,  8.02105420e+03,  2.54963672e+03, -3.65393457e+03,\n",
       "        -2.60429004e+04,  8.17574365e+03,  1.06900811e+04, -2.15388379e+04,\n",
       "        -1.02634424e+03,  4.00509448e+03, -3.04633184e+04, -5.01779297e+04,\n",
       "        -1.26333351e+01,  3.72267344e+04,  1.02889775e+04,  9.85885645e+03,\n",
       "        -1.78117793e+04,  2.34177521e+02,  1.60652617e+04,  1.31698545e+04,\n",
       "        -2.18575664e+04, -5.48586084e+03, -2.43504785e+03, -4.99591943e+03,\n",
       "        -2.16535254e+04,  5.07441328e+04,  1.50409839e+03,  1.15706123e+04,\n",
       "        -1.72820469e+04, -1.00454727e+04,  3.23702188e+04,  1.00685234e+04,\n",
       "        -2.69046113e+04,  8.09070703e+03,  1.56077383e+04, -3.92194961e+04,\n",
       "        -7.82342822e+03,  3.21429551e+04, -1.66794883e+04, -2.49235469e+04,\n",
       "         2.73050000e+04,  2.39109619e+03, -1.87903340e+04,  3.37155234e+04,\n",
       "        -1.44937383e+04, -6.43329346e+03,  1.66190859e+04,  3.39918359e+04,\n",
       "        -3.36964414e+04,  3.36774531e+04, -1.66363359e+04,  2.32893188e+03,\n",
       "         3.20967852e+04,  1.03268779e+04, -4.40705820e+04,  8.16277832e+03,\n",
       "        -9.75539844e+03, -2.04043965e+04,  4.12394287e+03,  3.61313892e+03,\n",
       "        -2.48093145e+04, -1.25154824e+04,  1.48527314e+04,  1.10751111e+03,\n",
       "         1.44498418e+04, -6.66142883e+02, -2.12783418e+04, -3.61560254e+03,\n",
       "         1.27533789e+04, -2.58802783e+03,  1.95683828e+04, -1.09830635e+04,\n",
       "        -4.45239922e+04, -1.74690703e+04,  7.12864453e+04,  1.16419883e+04,\n",
       "         1.67401094e+04, -1.86215645e+04, -2.31797051e+04,  1.37228857e+04,\n",
       "         3.30768086e+04,  9.52091504e+03,  3.76919336e+04, -7.27254883e+03,\n",
       "         5.55450098e+03, -1.51307117e+03,  3.60692227e+04, -2.67248027e+04,\n",
       "        -5.81852930e+03, -2.52635078e+04, -2.78742949e+04,  3.98924062e+04,\n",
       "         1.02901504e+04,  1.86098262e+04,  1.21358887e+04,  7.02744629e+03,\n",
       "         2.50405444e+03,  2.40215371e+04, -8.11532275e+03, -2.02021309e+04,\n",
       "        -1.29993677e+03, -1.78338652e+04, -1.52136841e+03,  2.27573965e+04,\n",
       "         1.68501719e+04, -5.25588555e+04, -8.75464941e+03, -4.12151445e+04,\n",
       "         2.64181836e+04,  1.43154022e+02, -5.12460547e+04, -2.37106641e+04,\n",
       "        -5.15133154e+03,  1.35107432e+04, -1.73069980e+04,  3.48746992e+04,\n",
       "        -8.92195215e+03,  2.42149316e+03,  4.64089258e+03, -2.10795586e+04,\n",
       "        -2.15393438e+04, -3.45540747e+03,  1.94579180e+04, -4.27859102e+04,\n",
       "        -1.96749336e+04, -2.07018477e+04, -2.17968906e+04,  2.65132891e+04,\n",
       "         7.73281494e+03,  1.59728809e+04,  9.08256836e+03, -6.11499707e+03,\n",
       "         6.64009326e+03, -1.27001895e+04, -6.27518652e+03, -5.28029727e+04,\n",
       "        -3.54573535e+03,  9.57213477e+03, -2.68220386e+03,  4.15468594e+04,\n",
       "         3.43821558e+03,  1.86031562e+04, -2.10998672e+04, -2.00751230e+04,\n",
       "        -1.98132363e+04,  4.33395068e+03,  1.04118896e+04, -2.33599844e+04,\n",
       "        -1.00024697e+04,  1.58459619e+04,  1.12262607e+04, -7.15590698e+02,\n",
       "         9.69110059e+03,  9.29242188e+03,  6.95710889e+03,  4.52142344e+04,\n",
       "         3.21589531e+04, -1.96939883e+04,  1.68356777e+04,  2.87808438e+04,\n",
       "        -1.92362324e+04, -3.03034609e+04, -1.10289856e+03,  2.61526797e+04,\n",
       "         9.55737109e+03,  4.19337500e+03, -4.62019570e+04,  2.85202480e+04,\n",
       "         2.61563418e+04, -1.27796133e+04,  5.80517188e+03, -1.55078477e+04,\n",
       "         7.47881775e+02, -1.99883848e+04, -2.33332471e+03, -2.02610684e+04,\n",
       "        -1.19719111e+04,  3.57297754e+03,  3.72189844e+04,  4.04592822e+03,\n",
       "         3.42205352e+04,  3.85874805e+04, -6.02522773e+04,  1.78981016e+04,\n",
       "         9.17824609e+03, -1.71773828e+04,  2.30686738e+04, -5.55462402e+03,\n",
       "         2.28265312e+04,  3.19215371e+04,  3.19737910e+04,  6.71484033e+03,\n",
       "        -3.98730713e+03, -7.05117188e+02,  3.31466016e+04, -1.89749180e+04,\n",
       "        -2.33320078e+04, -3.22129590e+04, -1.04129590e+04,  1.47306816e+04,\n",
       "         3.65148242e+04, -2.06397188e+04, -3.39147578e+04, -8.89144824e+03,\n",
       "         4.35602734e+04,  1.83949648e+04,  2.38823657e+03, -1.34193057e+04,\n",
       "         1.48431653e+03, -2.38010137e+04, -2.12207422e+04,  5.85720850e+03,\n",
       "         1.23441299e+04, -4.21416211e+04,  1.38401846e+04,  1.54646826e+04,\n",
       "         1.82328574e+04,  1.92223008e+04,  1.75865527e+04, -1.85350703e+04,\n",
       "        -9.59325879e+03,  1.48836787e+04,  2.01348027e+04,  2.63915957e+04,\n",
       "         4.69181016e+04, -5.50199756e+03, -2.68438164e+04,  1.77341230e+04,\n",
       "        -3.81159570e+04, -4.20515381e+03, -9.35699023e+03, -2.20577520e+04,\n",
       "         1.08689590e+04, -3.11197637e+04,  2.90929707e+04,  1.49455908e+04,\n",
       "        -2.36752383e+04,  1.60107256e+04,  1.60106367e+04, -2.17023945e+04,\n",
       "         2.16498359e+04,  1.66403359e+04,  2.31607129e+04, -8.75463574e+03,\n",
       "        -6.11023376e+02,  1.74573340e+04,  8.68118457e+03, -1.12895918e+04,\n",
       "        -2.55434922e+04, -1.85499570e+04, -1.95238887e+04, -2.15999375e+04,\n",
       "        -2.04822871e+04, -1.63475752e+04,  1.55479873e+04,  3.58583047e+04,\n",
       "        -4.40110117e+04, -1.59197559e+04,  1.59906812e+03,  8.73958398e+03,\n",
       "         2.86827051e+04,  8.19528809e+03,  5.77366455e+03,  1.85539941e+04,\n",
       "         3.65592070e+04, -1.06520713e+04, -4.89252109e+04, -1.91649199e+04,\n",
       "         3.00432520e+04, -2.59425762e+04, -4.23559375e+03,  4.06558867e+04,\n",
       "         2.57681426e+04, -1.34323799e+04,  4.86869453e+04,  1.46548633e+04,\n",
       "         1.80890000e+04,  5.33161963e+03, -8.52618164e+03,  3.75951172e+04,\n",
       "         4.75390479e+03,  3.30381836e+04,  1.02863672e+04, -9.41253711e+03,\n",
       "         1.14123379e+04, -5.36878857e+03, -5.66126099e+02,  6.01283838e+03,\n",
       "        -4.14691797e+04,  2.14790508e+04,  1.16396670e+04, -2.02382070e+04,\n",
       "         7.98950781e+03, -4.12898125e+04, -1.92364316e+04,  3.97144805e+04,\n",
       "        -2.01476777e+04, -2.32165879e+04,  3.39738516e+04,  5.53323047e+03,\n",
       "        -4.57078594e+04,  1.57080977e+04,  1.18624775e+04,  1.54946621e+04,\n",
       "         8.98198340e+03, -5.04807812e+04, -4.91894580e+03, -3.14660273e+04,\n",
       "         2.65621055e+04, -3.04590449e+04,  8.09294067e+02, -8.02323291e+03,\n",
       "         1.42698984e+04,  3.18213730e+04, -3.78791089e+03,  1.33310732e+04,\n",
       "        -3.31363320e+04,  9.54469043e+03, -3.84395312e+04,  4.15822314e+03,\n",
       "         4.44340088e+03, -7.10940186e+03, -2.71291724e+03, -1.16310510e+03,\n",
       "        -1.38706250e+04, -1.84777168e+04,  6.31599951e+03,  3.56426602e+04,\n",
       "         4.17882539e+04, -2.96294062e+04, -1.26748730e+03,  1.56786689e+04,\n",
       "         5.38619092e+03,  3.82322148e+04,  1.35577500e+04,  1.07612617e+04,\n",
       "         1.71875352e+04,  1.53069229e+04,  1.41821152e+04,  9.95689258e+03,\n",
       "        -9.70098694e+02,  4.71425117e+04,  2.13119727e+04,  2.76106348e+04,\n",
       "         1.16866035e+04,  6.73828809e+03, -2.16123184e+04, -5.97776221e+03,\n",
       "        -1.54572236e+04,  2.72805469e+03, -3.51758047e+04,  2.11478784e+03,\n",
       "        -1.57526631e+04,  2.35350117e+04,  1.82957656e+04, -3.31631616e+03,\n",
       "        -1.51295381e+04,  9.08741504e+03, -2.65156738e+04,  3.37513633e+04,\n",
       "         2.56240186e+03,  2.53083281e+04,  1.52790820e+04, -1.40506455e+04,\n",
       "         7.13063232e+03, -2.09626172e+04,  1.34139766e+04,  1.30420566e+04,\n",
       "         3.80961992e+04,  5.38047070e+03,  4.38040273e+04, -2.11702793e+04,\n",
       "        -7.68950195e+03,  1.01776556e+03, -4.39710254e+03, -1.69776934e+04,\n",
       "         2.30004785e+04, -1.74513086e+03, -1.97340605e+04,  1.79176523e+04,\n",
       "        -4.73939453e+04,  8.33244434e+03,  2.26565469e+04, -2.17381074e+04,\n",
       "         2.56765977e+04, -5.00370166e+03, -7.56049854e+03,  3.47327808e+03,\n",
       "        -1.06891611e+04, -2.32452969e+04, -2.86586797e+04,  1.84659141e+04,\n",
       "         5.43251250e+04,  1.03774756e+04,  1.44218042e+03, -1.20513320e+04,\n",
       "        -1.04795332e+04, -1.03051289e+04,  6.85646533e+03,  4.07919609e+04,\n",
       "         5.40295410e+02,  1.21281946e+03, -2.12040742e+04, -2.02359004e+04,\n",
       "        -4.10860742e+03,  1.79615762e+04, -1.79507441e+04, -1.77339688e+04,\n",
       "        -3.66348672e+04,  3.02806621e+04,  3.15296348e+04,  2.86914648e+04,\n",
       "         3.33536367e+04,  1.90941968e+03, -1.32877607e+04,  1.35513896e+04,\n",
       "        -6.35630420e+03, -2.27718726e+03, -9.67497949e+03,  1.51267617e+04,\n",
       "         1.30107744e+04, -5.01096445e+04,  9.51156641e+03, -1.99965859e+04,\n",
       "         8.02016992e+03, -2.14139941e+04,  1.10884492e+04, -2.80882480e+04,\n",
       "        -1.19247656e+04, -4.39214453e+04,  1.07557129e+03,  1.77834688e+04,\n",
       "         2.19029844e+04, -2.10944434e+04,  1.58481699e+04,  3.60696758e+04,\n",
       "        -5.91804980e+03,  8.12959180e+03, -1.09930049e+04,  3.99516138e+03,\n",
       "         1.06149355e+04, -1.56427920e+04, -8.75064551e+03, -6.65554749e+02,\n",
       "         3.80549707e+03,  2.52350879e+04, -1.31624629e+04, -1.63667363e+04,\n",
       "         2.26851953e+04,  3.60335254e+03,  5.46545459e+03, -3.68503828e+04,\n",
       "        -6.61883545e+02, -2.48707637e+04,  5.25859131e+03,  3.69006211e+04,\n",
       "        -2.02018730e+04,  2.98187363e+04, -8.99462708e+02,  2.88811475e+03,\n",
       "        -1.61854180e+04, -8.92516602e+03, -9.57391113e+03, -3.36285625e+04,\n",
       "        -2.00936777e+04,  3.11880151e+03,  3.23488750e+04, -2.69301660e+04,\n",
       "        -9.10551953e+03, -4.01717344e+04,  9.04346777e+03, -2.84768691e+04,\n",
       "        -2.82255918e+04, -6.44387354e+03,  4.38300439e+03, -1.23764756e+04,\n",
       "        -1.56721133e+04,  6.64553613e+03,  1.64015430e+04, -1.18963916e+03,\n",
       "         2.76103457e+04,  2.12154570e+04, -4.79350342e+03, -1.60925371e+04,\n",
       "         2.71357344e+04,  1.75621504e+04, -1.23697236e+04, -3.99508281e+04,\n",
       "        -6.63722314e+03, -3.18312085e+03,  2.46380840e+04,  4.15121033e+02,\n",
       "        -3.54971484e+04,  2.08311250e+04,  3.39031830e+02,  3.67689609e+04,\n",
       "         1.38684375e+04, -2.43042422e+04, -2.20817822e+03, -4.07999976e+03,\n",
       "         1.63777510e+04, -1.52424775e+04,  5.42443994e+03,  2.72884595e+03,\n",
       "        -3.08267163e+03,  1.18165747e+03, -1.52305359e+03, -6.32566260e+03,\n",
       "        -8.21784851e+02,  4.86351166e+02, -4.53720352e+04,  7.87622803e+03,\n",
       "        -1.80783667e+03,  2.01638340e+04,  5.01221055e+04, -1.49283623e+04,\n",
       "        -2.35232168e+04, -3.45048750e+04, -5.20989111e+03, -2.62231543e+04,\n",
       "         2.90249473e+04,  2.40090859e+04, -8.58720703e+03,  1.00098187e+03,\n",
       "         1.28001514e+03,  2.05425078e+04,  4.52339746e+03, -6.20473730e+03,\n",
       "         1.33583906e+04,  1.04952715e+04,  2.15265918e+04, -3.50162070e+04,\n",
       "         1.72188281e+04,  1.79243750e+04,  1.59192285e+04, -1.37985898e+04,\n",
       "         1.36427529e+04, -3.05758643e+03, -1.14369355e+04,  4.53005859e+03,\n",
       "         1.57119062e+04, -2.43402246e+04, -2.69622119e+03, -3.10323711e+04,\n",
       "        -2.71867578e+04,  1.87912285e+04, -3.24646606e+03, -3.03663008e+04,\n",
       "        -1.19498623e+04,  2.46102754e+04, -3.62305273e+03, -4.00860156e+04,\n",
       "         1.38567949e+04, -1.59622832e+04, -2.25153066e+04,  3.54605312e+04,\n",
       "         1.99378418e+04, -1.20948066e+04, -2.56916626e+03,  1.31685674e+04,\n",
       "         7.74446436e+03, -2.95590273e+04, -1.87456562e+04,  3.42022876e+03,\n",
       "         1.11844443e+04, -2.16217910e+04, -1.91056152e+04,  5.57661426e+03,\n",
       "        -1.71969609e+04,  7.79522888e+02,  2.63327793e+04,  1.15130020e+04,\n",
       "         2.02259492e+04, -2.87585410e+04, -1.93457480e+04, -4.23269971e+03,\n",
       "         1.01808193e+04,  7.52427441e+03, -6.32027930e+03, -1.61407852e+04,\n",
       "        -1.01720371e+04, -9.34071533e+02,  1.41709678e+04,  1.30360713e+04,\n",
       "        -3.62185742e+04,  4.56872705e+03,  1.59461987e+03,  2.11376016e+04,\n",
       "         4.61385586e+04,  1.06277710e+03, -6.20453027e+03, -3.06656758e+04,\n",
       "         9.74807910e+03, -1.31586064e+04,  1.97484436e+03,  4.46977979e+03,\n",
       "         1.80743613e+04, -1.77397344e+04, -2.70744883e+04,  1.50750889e+04,\n",
       "        -1.24452969e+04, -3.17824707e+04,  9.40884668e+03, -2.36917852e+04,\n",
       "        -2.68609453e+04, -2.73635098e+04, -1.53738809e+04,  8.69046289e+03,\n",
       "         4.05059453e+04,  2.81600117e+04,  2.03752429e+03, -2.21881289e+04,\n",
       "        -3.82992456e+03,  1.28830898e+04, -6.86906875e+04, -1.61911953e+04,\n",
       "         1.76596758e+04, -1.20783818e+04,  8.14480225e+03,  7.50400452e+02,\n",
       "        -2.87271680e+03,  6.45530225e+03, -1.25002383e+04, -7.95221497e+02,\n",
       "         1.65054062e+04, -1.32145137e+04, -1.33691426e+04, -4.04991919e+03,\n",
       "        -1.86630352e+04,  1.04150420e+04,  2.29736270e+04,  6.86459375e+03,\n",
       "         6.30775625e+04, -2.06641406e+04, -4.56062158e+03, -1.69664375e+04,\n",
       "        -9.01172559e+03, -2.40597461e+03,  1.39676465e+04,  1.85148027e+04,\n",
       "         3.18810156e+04, -2.34703008e+04,  1.70982051e+04,  8.10262695e+03,\n",
       "        -1.71547930e+04,  4.07516113e+03, -1.11792881e+04, -2.37623926e+04,\n",
       "        -1.94742261e+03,  1.13783770e+04,  1.43067383e+04,  1.30643115e+04,\n",
       "        -1.38443506e+04,  3.99227852e+04, -1.81256775e+03, -2.61120605e+04,\n",
       "         2.09644277e+04,  4.43804779e+02,  1.41279053e+04,  5.87451562e+03,\n",
       "         1.44521689e+04, -9.59456934e+03, -1.48919463e+04, -7.93159766e+03,\n",
       "         2.28515894e+03, -1.96406562e+04, -2.68824414e+03, -1.22677764e+04,\n",
       "         2.86736094e+04, -3.46732500e+04, -6.04075879e+03,  8.19773315e+02,\n",
       "        -6.34399805e+03,  2.10403359e+04,  9.19237109e+03,  3.17237964e+03,\n",
       "         8.69423633e+03,  3.67392812e+04,  2.74427881e+03, -1.77218496e+04,\n",
       "        -2.88293066e+04, -1.00386322e+03, -1.03245234e+04,  8.43765430e+03,\n",
       "        -1.53473809e+04, -3.91761499e+03, -1.10422314e+04,  1.28453203e+04,\n",
       "         1.11074658e+03, -2.06103540e+03,  1.93685859e+04,  3.52818438e+04,\n",
       "         1.93852480e+04, -1.74024961e+04,  5.69930176e+02,  1.84316094e+04,\n",
       "        -2.49245488e+04,  3.72816260e+03,  1.81801035e+04, -1.56504346e+03,\n",
       "        -8.13485205e+03,  1.60956504e+04, -1.45176729e+04, -6.29195996e+03,\n",
       "        -2.61698516e+04,  1.54664199e+04, -1.10757012e+04, -3.70022852e+04,\n",
       "        -1.33544580e+04, -9.77780566e+03,  2.07301465e+04, -3.52663672e+04,\n",
       "        -4.14773164e+04, -9.54965332e+03,  4.82876367e+03,  1.24503008e+04,\n",
       "        -3.54934668e+03, -3.50380391e+04,  3.98787476e+02,  1.23682458e+03,\n",
       "         8.36051562e+03,  4.60204053e+03,  1.80294648e+04, -1.31895225e+04,\n",
       "         1.95655371e+04, -1.19803311e+04, -1.49793115e+03,  7.93389941e+03,\n",
       "         8.15116260e+03, -4.88260547e+03,  2.40702319e+03,  1.23643730e+04,\n",
       "        -2.70888086e+04,  9.66894727e+03, -2.58958242e+04, -2.54293613e+04,\n",
       "        -1.55227129e+04, -7.87418945e+03, -4.50824375e+04,  5.02260000e+04,\n",
       "         3.52386255e+03, -2.01380188e+03,  4.13158086e+04,  1.71539473e+04,\n",
       "        -1.71725757e+03,  1.68965957e+04, -1.44219995e+03,  8.58207910e+03,\n",
       "         1.80952773e+04, -2.08987402e+04, -2.08101094e+04, -3.90282861e+03,\n",
       "         1.85657305e+04,  3.29393086e+04, -1.45254797e+03, -1.58665059e+04,\n",
       "         2.27769141e+03, -1.85644336e+04, -4.98300664e+04, -4.54277246e+03,\n",
       "        -4.09721484e+03, -1.29993477e+04, -3.47584922e+04,  9.99974121e+02,\n",
       "        -2.27759180e+04,  3.37734727e+04,  2.37086445e+04, -5.89384668e+03,\n",
       "        -1.31178896e+04, -3.12491680e+04,  2.52245508e+04, -2.38316426e+04,\n",
       "        -1.79612246e+04, -2.75606035e+04, -1.31408262e+04,  3.66054258e+04,\n",
       "        -5.03539551e+03,  6.40769482e+03, -1.14647031e+04, -2.75141758e+04,\n",
       "        -8.87353223e+03,  1.61278477e+04, -7.43338672e+03,  4.57143097e+02,\n",
       "        -2.58071753e+03, -1.17943418e+04,  2.00158340e+04, -1.44686982e+04,\n",
       "         3.08764404e+03,  8.61856055e+03, -3.03977871e+04, -2.72532383e+04,\n",
       "         2.16765938e+04,  4.35619043e+03,  3.12900352e+04,  9.12002539e+03,\n",
       "        -2.27094980e+04, -3.68046582e+03, -2.55892012e+04,  5.99476465e+03,\n",
       "        -6.84112354e+03,  4.19064990e+03, -9.15352234e+02, -2.78731602e+04,\n",
       "         1.35966504e+04,  8.21862109e+03,  2.97519785e+04, -2.28545625e+04,\n",
       "        -7.03721387e+03,  1.55392285e+04,  3.54243927e+02, -9.52654980e+03,\n",
       "         1.18931768e+04,  5.65388379e+03,  2.13698730e+04,  1.41984990e+04,\n",
       "         1.57990869e+04, -1.95683789e+04,  4.50743262e+03,  1.00964020e+03,\n",
       "         6.58390869e+02, -1.15010576e+04,  1.97254414e+04,  2.16741797e+04,\n",
       "        -1.19884639e+04, -5.15960693e+03,  4.77714453e+03,  3.33727490e+03,\n",
       "        -1.38403652e+04, -2.28025820e+04,  2.99940967e+03,  9.34161914e+03,\n",
       "        -2.32576191e+04,  3.30513008e+04, -2.62694043e+04,  5.20950781e+03,\n",
       "         6.01543994e+03,  3.17629590e+04,  8.34510156e+03,  1.67043242e+04,\n",
       "        -4.89561621e+03, -1.32048301e+04,  1.55089883e+04, -1.03993713e+03,\n",
       "         4.03487695e+04,  4.20435791e+03, -2.63396602e+04, -2.96698125e+04,\n",
       "         3.92505117e+04,  3.44631934e+03,  6.88872607e+03, -2.96879883e+04,\n",
       "         8.27688379e+03, -2.26954883e+04, -4.18414336e+04, -1.84737559e+04,\n",
       "         1.43382148e+04, -1.57139229e+04, -1.24003076e+04,  1.90501582e+04,\n",
       "         1.22094326e+04,  8.34229187e+02,  1.36260996e+04,  1.17123438e+03,\n",
       "        -1.35455176e+03,  1.37530969e+03,  4.53889805e+04, -2.55510254e+04,\n",
       "         1.26727393e+04, -2.17051727e+02,  1.83638203e+04, -1.26535820e+04,\n",
       "        -1.58385941e+02, -1.00421172e+04,  1.50440996e+04,  1.52543135e+04,\n",
       "        -1.37105391e+04, -2.93311504e+04, -1.56233262e+04,  5.38389111e+03,\n",
       "         5.43978711e+04, -2.27829824e+04, -1.34924297e+04,  2.83553555e+04,\n",
       "         3.47670234e+04,  2.15348438e+04,  9.24781836e+03,  3.54815938e+04,\n",
       "        -2.96657852e+04, -3.94595795e+02,  3.48810000e+04, -1.19425049e+04,\n",
       "         1.04949580e+04, -1.57767275e+04,  3.07647441e+04,  1.89283359e+04,\n",
       "        -1.33088164e+04, -1.72154570e+04, -1.01675391e+04,  2.01049160e+04],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ded5744e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>F_0</th>\n",
       "      <th>F_1</th>\n",
       "      <th>F_2</th>\n",
       "      <th>F_3</th>\n",
       "      <th>F_4</th>\n",
       "      <th>F_5</th>\n",
       "      <th>F_6</th>\n",
       "      <th>F_7</th>\n",
       "      <th>F_8</th>\n",
       "      <th>...</th>\n",
       "      <th>F_990</th>\n",
       "      <th>F_991</th>\n",
       "      <th>F_992</th>\n",
       "      <th>F_993</th>\n",
       "      <th>F_994</th>\n",
       "      <th>F_995</th>\n",
       "      <th>F_996</th>\n",
       "      <th>F_997</th>\n",
       "      <th>F_998</th>\n",
       "      <th>F_999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "      <td>-10690.636719</td>\n",
       "      <td>-25213.765625</td>\n",
       "      <td>29258.396484</td>\n",
       "      <td>22853.923828</td>\n",
       "      <td>-22368.410156</td>\n",
       "      <td>-11693.577148</td>\n",
       "      <td>8507.174805</td>\n",
       "      <td>-2724.493896</td>\n",
       "      <td>-37924.949219</td>\n",
       "      <td>...</td>\n",
       "      <td>34881.000000</td>\n",
       "      <td>-11942.504883</td>\n",
       "      <td>10494.958008</td>\n",
       "      <td>-15776.727539</td>\n",
       "      <td>30764.744141</td>\n",
       "      <td>18928.335938</td>\n",
       "      <td>-13308.816406</td>\n",
       "      <td>-17215.457031</td>\n",
       "      <td>-10167.539062</td>\n",
       "      <td>20104.916016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>-7629.322754</td>\n",
       "      <td>-18402.431641</td>\n",
       "      <td>21075.640625</td>\n",
       "      <td>17044.130859</td>\n",
       "      <td>-17074.062500</td>\n",
       "      <td>-8875.350586</td>\n",
       "      <td>6207.130371</td>\n",
       "      <td>-2534.134033</td>\n",
       "      <td>-28035.839844</td>\n",
       "      <td>...</td>\n",
       "      <td>25396.242188</td>\n",
       "      <td>-8040.164062</td>\n",
       "      <td>7526.416504</td>\n",
       "      <td>-11134.735352</td>\n",
       "      <td>21891.035156</td>\n",
       "      <td>13781.102539</td>\n",
       "      <td>-9286.528320</td>\n",
       "      <td>-12237.918945</td>\n",
       "      <td>-7031.791992</td>\n",
       "      <td>14757.584961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N</td>\n",
       "      <td>-7409.713867</td>\n",
       "      <td>-17593.281250</td>\n",
       "      <td>19657.062500</td>\n",
       "      <td>16256.388672</td>\n",
       "      <td>-16373.372070</td>\n",
       "      <td>-8285.156250</td>\n",
       "      <td>5567.615234</td>\n",
       "      <td>-2038.848877</td>\n",
       "      <td>-26340.152344</td>\n",
       "      <td>...</td>\n",
       "      <td>23134.189453</td>\n",
       "      <td>-7232.945801</td>\n",
       "      <td>7283.832031</td>\n",
       "      <td>-10198.464844</td>\n",
       "      <td>20487.828125</td>\n",
       "      <td>12480.434570</td>\n",
       "      <td>-8593.717773</td>\n",
       "      <td>-11392.190430</td>\n",
       "      <td>-6298.755371</td>\n",
       "      <td>13492.181641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>-9487.986328</td>\n",
       "      <td>-21533.810547</td>\n",
       "      <td>24994.900391</td>\n",
       "      <td>19448.421875</td>\n",
       "      <td>-19460.894531</td>\n",
       "      <td>-10532.538086</td>\n",
       "      <td>7491.643066</td>\n",
       "      <td>-2692.489014</td>\n",
       "      <td>-32500.560547</td>\n",
       "      <td>...</td>\n",
       "      <td>29641.876953</td>\n",
       "      <td>-9823.654297</td>\n",
       "      <td>8988.515625</td>\n",
       "      <td>-13260.978516</td>\n",
       "      <td>26138.876953</td>\n",
       "      <td>16142.136719</td>\n",
       "      <td>-11179.166016</td>\n",
       "      <td>-14604.679688</td>\n",
       "      <td>-8382.214844</td>\n",
       "      <td>17354.947266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N</td>\n",
       "      <td>-11941.234375</td>\n",
       "      <td>-29637.691406</td>\n",
       "      <td>35033.589844</td>\n",
       "      <td>27598.150391</td>\n",
       "      <td>-26310.652344</td>\n",
       "      <td>-13651.644531</td>\n",
       "      <td>10284.687500</td>\n",
       "      <td>-3895.448486</td>\n",
       "      <td>-44680.093750</td>\n",
       "      <td>...</td>\n",
       "      <td>41469.593750</td>\n",
       "      <td>-14147.382812</td>\n",
       "      <td>12032.883789</td>\n",
       "      <td>-18577.267578</td>\n",
       "      <td>35908.304688</td>\n",
       "      <td>22637.023438</td>\n",
       "      <td>-15558.220703</td>\n",
       "      <td>-20085.800781</td>\n",
       "      <td>-11846.132812</td>\n",
       "      <td>23801.306641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label           F_0           F_1           F_2           F_3           F_4  \\\n",
       "0     N -10690.636719 -25213.765625  29258.396484  22853.923828 -22368.410156   \n",
       "1     N  -7629.322754 -18402.431641  21075.640625  17044.130859 -17074.062500   \n",
       "2     N  -7409.713867 -17593.281250  19657.062500  16256.388672 -16373.372070   \n",
       "3     N  -9487.986328 -21533.810547  24994.900391  19448.421875 -19460.894531   \n",
       "4     N -11941.234375 -29637.691406  35033.589844  27598.150391 -26310.652344   \n",
       "\n",
       "            F_5           F_6          F_7           F_8  ...         F_990  \\\n",
       "0 -11693.577148   8507.174805 -2724.493896 -37924.949219  ...  34881.000000   \n",
       "1  -8875.350586   6207.130371 -2534.134033 -28035.839844  ...  25396.242188   \n",
       "2  -8285.156250   5567.615234 -2038.848877 -26340.152344  ...  23134.189453   \n",
       "3 -10532.538086   7491.643066 -2692.489014 -32500.560547  ...  29641.876953   \n",
       "4 -13651.644531  10284.687500 -3895.448486 -44680.093750  ...  41469.593750   \n",
       "\n",
       "          F_991         F_992         F_993         F_994         F_995  \\\n",
       "0 -11942.504883  10494.958008 -15776.727539  30764.744141  18928.335938   \n",
       "1  -8040.164062   7526.416504 -11134.735352  21891.035156  13781.102539   \n",
       "2  -7232.945801   7283.832031 -10198.464844  20487.828125  12480.434570   \n",
       "3  -9823.654297   8988.515625 -13260.978516  26138.876953  16142.136719   \n",
       "4 -14147.382812  12032.883789 -18577.267578  35908.304688  22637.023438   \n",
       "\n",
       "          F_996         F_997         F_998         F_999  \n",
       "0 -13308.816406 -17215.457031 -10167.539062  20104.916016  \n",
       "1  -9286.528320 -12237.918945  -7031.791992  14757.584961  \n",
       "2  -8593.717773 -11392.190430  -6298.755371  13492.181641  \n",
       "3 -11179.166016 -14604.679688  -8382.214844  17354.947266  \n",
       "4 -15558.220703 -20085.800781 -11846.132812  23801.306641  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "# Iterate over the list of dictionaries\n",
    "for idx, d in enumerate(Train_features):\n",
    "    # Extract the label and features from each dictionary\n",
    "    label = d['Label']\n",
    "    features = d['Features']\n",
    "    \n",
    "    # Create a dictionary for the row data\n",
    "    row_data = {'Label': label}\n",
    "    \n",
    "    # Add the features as columns to the row dictionary\n",
    "    for i, value in enumerate(features):\n",
    "        column_name = f'F_{i}'\n",
    "        row_data[column_name] = value\n",
    "    \n",
    "    # Append the row to the DataFrame\n",
    "    df = df.append(row_data, ignore_index=True)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "797ac9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>F_0</th>\n",
       "      <th>F_1</th>\n",
       "      <th>F_2</th>\n",
       "      <th>F_3</th>\n",
       "      <th>F_4</th>\n",
       "      <th>F_5</th>\n",
       "      <th>F_6</th>\n",
       "      <th>F_7</th>\n",
       "      <th>F_8</th>\n",
       "      <th>...</th>\n",
       "      <th>F_990</th>\n",
       "      <th>F_991</th>\n",
       "      <th>F_992</th>\n",
       "      <th>F_993</th>\n",
       "      <th>F_994</th>\n",
       "      <th>F_995</th>\n",
       "      <th>F_996</th>\n",
       "      <th>F_997</th>\n",
       "      <th>F_998</th>\n",
       "      <th>F_999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13822</th>\n",
       "      <td>N</td>\n",
       "      <td>-10404.021484</td>\n",
       "      <td>-23338.478516</td>\n",
       "      <td>26978.138672</td>\n",
       "      <td>21753.648438</td>\n",
       "      <td>-22130.128906</td>\n",
       "      <td>-10867.045898</td>\n",
       "      <td>7291.555176</td>\n",
       "      <td>-2227.296875</td>\n",
       "      <td>-35857.980469</td>\n",
       "      <td>...</td>\n",
       "      <td>31758.216797</td>\n",
       "      <td>-10215.650391</td>\n",
       "      <td>10416.590820</td>\n",
       "      <td>-14363.471680</td>\n",
       "      <td>28445.808594</td>\n",
       "      <td>16768.814453</td>\n",
       "      <td>-11932.501953</td>\n",
       "      <td>-16069.323242</td>\n",
       "      <td>-9301.821289</td>\n",
       "      <td>19169.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13823</th>\n",
       "      <td>T</td>\n",
       "      <td>-16160.044922</td>\n",
       "      <td>-37650.609375</td>\n",
       "      <td>44081.273438</td>\n",
       "      <td>34148.871094</td>\n",
       "      <td>-33653.707031</td>\n",
       "      <td>-17329.068359</td>\n",
       "      <td>12416.479492</td>\n",
       "      <td>-4097.287598</td>\n",
       "      <td>-56819.593750</td>\n",
       "      <td>...</td>\n",
       "      <td>52097.046875</td>\n",
       "      <td>-17646.437500</td>\n",
       "      <td>15809.777344</td>\n",
       "      <td>-23504.994141</td>\n",
       "      <td>45653.710938</td>\n",
       "      <td>28152.269531</td>\n",
       "      <td>-19507.972656</td>\n",
       "      <td>-26091.615234</td>\n",
       "      <td>-15724.344727</td>\n",
       "      <td>30584.486328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13824</th>\n",
       "      <td>N</td>\n",
       "      <td>-7369.031738</td>\n",
       "      <td>-16503.121094</td>\n",
       "      <td>19281.771484</td>\n",
       "      <td>15614.791016</td>\n",
       "      <td>-16197.250000</td>\n",
       "      <td>-7546.625488</td>\n",
       "      <td>5154.735352</td>\n",
       "      <td>-1926.464844</td>\n",
       "      <td>-25304.265625</td>\n",
       "      <td>...</td>\n",
       "      <td>22346.271484</td>\n",
       "      <td>-6845.833496</td>\n",
       "      <td>7722.492676</td>\n",
       "      <td>-10210.019531</td>\n",
       "      <td>19939.275391</td>\n",
       "      <td>11934.598633</td>\n",
       "      <td>-8350.815430</td>\n",
       "      <td>-11268.934570</td>\n",
       "      <td>-6698.681641</td>\n",
       "      <td>14051.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13825</th>\n",
       "      <td>N</td>\n",
       "      <td>-11295.024414</td>\n",
       "      <td>-27929.931641</td>\n",
       "      <td>33156.992188</td>\n",
       "      <td>25682.466797</td>\n",
       "      <td>-24629.812500</td>\n",
       "      <td>-12899.165039</td>\n",
       "      <td>9742.039062</td>\n",
       "      <td>-3303.626709</td>\n",
       "      <td>-41991.593750</td>\n",
       "      <td>...</td>\n",
       "      <td>39164.136719</td>\n",
       "      <td>-13299.090820</td>\n",
       "      <td>11353.364258</td>\n",
       "      <td>-17584.500000</td>\n",
       "      <td>34069.644531</td>\n",
       "      <td>21509.464844</td>\n",
       "      <td>-14844.583984</td>\n",
       "      <td>-19079.046875</td>\n",
       "      <td>-11296.425781</td>\n",
       "      <td>22739.292969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13826</th>\n",
       "      <td>N</td>\n",
       "      <td>-11531.065430</td>\n",
       "      <td>-26543.714844</td>\n",
       "      <td>29964.583984</td>\n",
       "      <td>24526.183594</td>\n",
       "      <td>-25373.324219</td>\n",
       "      <td>-12047.337891</td>\n",
       "      <td>7985.197754</td>\n",
       "      <td>-2640.860107</td>\n",
       "      <td>-39977.628906</td>\n",
       "      <td>...</td>\n",
       "      <td>34985.781250</td>\n",
       "      <td>-10964.642578</td>\n",
       "      <td>11470.073242</td>\n",
       "      <td>-15836.332031</td>\n",
       "      <td>31279.884766</td>\n",
       "      <td>18891.460938</td>\n",
       "      <td>-13139.791016</td>\n",
       "      <td>-17808.771484</td>\n",
       "      <td>-10510.906250</td>\n",
       "      <td>21594.855469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13827</th>\n",
       "      <td>N</td>\n",
       "      <td>-7913.774902</td>\n",
       "      <td>-18795.771484</td>\n",
       "      <td>21092.375000</td>\n",
       "      <td>17432.974609</td>\n",
       "      <td>-17709.652344</td>\n",
       "      <td>-8537.285156</td>\n",
       "      <td>5703.744141</td>\n",
       "      <td>-1913.878418</td>\n",
       "      <td>-28235.363281</td>\n",
       "      <td>...</td>\n",
       "      <td>24887.076172</td>\n",
       "      <td>-7891.482910</td>\n",
       "      <td>8098.312500</td>\n",
       "      <td>-11107.340820</td>\n",
       "      <td>22069.673828</td>\n",
       "      <td>13317.243164</td>\n",
       "      <td>-9317.119141</td>\n",
       "      <td>-12448.583984</td>\n",
       "      <td>-7344.066406</td>\n",
       "      <td>14753.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13828</th>\n",
       "      <td>N</td>\n",
       "      <td>-8127.605957</td>\n",
       "      <td>-18284.626953</td>\n",
       "      <td>21075.283203</td>\n",
       "      <td>17009.740234</td>\n",
       "      <td>-17330.498047</td>\n",
       "      <td>-8499.487305</td>\n",
       "      <td>5624.021973</td>\n",
       "      <td>-1689.323730</td>\n",
       "      <td>-27940.847656</td>\n",
       "      <td>...</td>\n",
       "      <td>24652.466797</td>\n",
       "      <td>-7982.913574</td>\n",
       "      <td>8117.382324</td>\n",
       "      <td>-11183.851562</td>\n",
       "      <td>22202.949219</td>\n",
       "      <td>12958.379883</td>\n",
       "      <td>-9235.305664</td>\n",
       "      <td>-12523.611328</td>\n",
       "      <td>-7219.841797</td>\n",
       "      <td>14884.139648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13829</th>\n",
       "      <td>N</td>\n",
       "      <td>-7838.163574</td>\n",
       "      <td>-17738.267578</td>\n",
       "      <td>20008.613281</td>\n",
       "      <td>16096.833984</td>\n",
       "      <td>-16626.548828</td>\n",
       "      <td>-8046.173828</td>\n",
       "      <td>5014.510742</td>\n",
       "      <td>-1214.207275</td>\n",
       "      <td>-26748.257812</td>\n",
       "      <td>...</td>\n",
       "      <td>23486.769531</td>\n",
       "      <td>-7628.034180</td>\n",
       "      <td>7584.827637</td>\n",
       "      <td>-10528.854492</td>\n",
       "      <td>20979.726562</td>\n",
       "      <td>12384.614258</td>\n",
       "      <td>-8713.296875</td>\n",
       "      <td>-12124.872070</td>\n",
       "      <td>-7216.768066</td>\n",
       "      <td>14084.831055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13830</th>\n",
       "      <td>N</td>\n",
       "      <td>-10912.828125</td>\n",
       "      <td>-26230.761719</td>\n",
       "      <td>30469.412109</td>\n",
       "      <td>23902.880859</td>\n",
       "      <td>-23354.072266</td>\n",
       "      <td>-12312.500977</td>\n",
       "      <td>8830.892578</td>\n",
       "      <td>-3127.529541</td>\n",
       "      <td>-39456.234375</td>\n",
       "      <td>...</td>\n",
       "      <td>36355.976562</td>\n",
       "      <td>-12274.033203</td>\n",
       "      <td>10649.001953</td>\n",
       "      <td>-16334.696289</td>\n",
       "      <td>31622.322266</td>\n",
       "      <td>20030.740234</td>\n",
       "      <td>-13482.427734</td>\n",
       "      <td>-17892.792969</td>\n",
       "      <td>-10645.318359</td>\n",
       "      <td>21083.908203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13831</th>\n",
       "      <td>N</td>\n",
       "      <td>-14110.157227</td>\n",
       "      <td>-32665.962891</td>\n",
       "      <td>38424.914062</td>\n",
       "      <td>29519.992188</td>\n",
       "      <td>-28756.906250</td>\n",
       "      <td>-15167.238281</td>\n",
       "      <td>10969.397461</td>\n",
       "      <td>-3567.516357</td>\n",
       "      <td>-49158.820312</td>\n",
       "      <td>...</td>\n",
       "      <td>45420.019531</td>\n",
       "      <td>-15473.536133</td>\n",
       "      <td>13587.240234</td>\n",
       "      <td>-20801.265625</td>\n",
       "      <td>39611.562500</td>\n",
       "      <td>24667.794922</td>\n",
       "      <td>-17107.271484</td>\n",
       "      <td>-22678.830078</td>\n",
       "      <td>-13596.544922</td>\n",
       "      <td>26554.994141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label           F_0           F_1           F_2           F_3  \\\n",
       "13822     N -10404.021484 -23338.478516  26978.138672  21753.648438   \n",
       "13823     T -16160.044922 -37650.609375  44081.273438  34148.871094   \n",
       "13824     N  -7369.031738 -16503.121094  19281.771484  15614.791016   \n",
       "13825     N -11295.024414 -27929.931641  33156.992188  25682.466797   \n",
       "13826     N -11531.065430 -26543.714844  29964.583984  24526.183594   \n",
       "13827     N  -7913.774902 -18795.771484  21092.375000  17432.974609   \n",
       "13828     N  -8127.605957 -18284.626953  21075.283203  17009.740234   \n",
       "13829     N  -7838.163574 -17738.267578  20008.613281  16096.833984   \n",
       "13830     N -10912.828125 -26230.761719  30469.412109  23902.880859   \n",
       "13831     N -14110.157227 -32665.962891  38424.914062  29519.992188   \n",
       "\n",
       "                F_4           F_5           F_6          F_7           F_8  \\\n",
       "13822 -22130.128906 -10867.045898   7291.555176 -2227.296875 -35857.980469   \n",
       "13823 -33653.707031 -17329.068359  12416.479492 -4097.287598 -56819.593750   \n",
       "13824 -16197.250000  -7546.625488   5154.735352 -1926.464844 -25304.265625   \n",
       "13825 -24629.812500 -12899.165039   9742.039062 -3303.626709 -41991.593750   \n",
       "13826 -25373.324219 -12047.337891   7985.197754 -2640.860107 -39977.628906   \n",
       "13827 -17709.652344  -8537.285156   5703.744141 -1913.878418 -28235.363281   \n",
       "13828 -17330.498047  -8499.487305   5624.021973 -1689.323730 -27940.847656   \n",
       "13829 -16626.548828  -8046.173828   5014.510742 -1214.207275 -26748.257812   \n",
       "13830 -23354.072266 -12312.500977   8830.892578 -3127.529541 -39456.234375   \n",
       "13831 -28756.906250 -15167.238281  10969.397461 -3567.516357 -49158.820312   \n",
       "\n",
       "       ...         F_990         F_991         F_992         F_993  \\\n",
       "13822  ...  31758.216797 -10215.650391  10416.590820 -14363.471680   \n",
       "13823  ...  52097.046875 -17646.437500  15809.777344 -23504.994141   \n",
       "13824  ...  22346.271484  -6845.833496   7722.492676 -10210.019531   \n",
       "13825  ...  39164.136719 -13299.090820  11353.364258 -17584.500000   \n",
       "13826  ...  34985.781250 -10964.642578  11470.073242 -15836.332031   \n",
       "13827  ...  24887.076172  -7891.482910   8098.312500 -11107.340820   \n",
       "13828  ...  24652.466797  -7982.913574   8117.382324 -11183.851562   \n",
       "13829  ...  23486.769531  -7628.034180   7584.827637 -10528.854492   \n",
       "13830  ...  36355.976562 -12274.033203  10649.001953 -16334.696289   \n",
       "13831  ...  45420.019531 -15473.536133  13587.240234 -20801.265625   \n",
       "\n",
       "              F_994         F_995         F_996         F_997         F_998  \\\n",
       "13822  28445.808594  16768.814453 -11932.501953 -16069.323242  -9301.821289   \n",
       "13823  45653.710938  28152.269531 -19507.972656 -26091.615234 -15724.344727   \n",
       "13824  19939.275391  11934.598633  -8350.815430 -11268.934570  -6698.681641   \n",
       "13825  34069.644531  21509.464844 -14844.583984 -19079.046875 -11296.425781   \n",
       "13826  31279.884766  18891.460938 -13139.791016 -17808.771484 -10510.906250   \n",
       "13827  22069.673828  13317.243164  -9317.119141 -12448.583984  -7344.066406   \n",
       "13828  22202.949219  12958.379883  -9235.305664 -12523.611328  -7219.841797   \n",
       "13829  20979.726562  12384.614258  -8713.296875 -12124.872070  -7216.768066   \n",
       "13830  31622.322266  20030.740234 -13482.427734 -17892.792969 -10645.318359   \n",
       "13831  39611.562500  24667.794922 -17107.271484 -22678.830078 -13596.544922   \n",
       "\n",
       "              F_999  \n",
       "13822  19169.078125  \n",
       "13823  30584.486328  \n",
       "13824  14051.406250  \n",
       "13825  22739.292969  \n",
       "13826  21594.855469  \n",
       "13827  14753.078125  \n",
       "13828  14884.139648  \n",
       "13829  14084.831055  \n",
       "13830  21083.908203  \n",
       "13831  26554.994141  \n",
       "\n",
       "[10 rows x 1001 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c63ca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del Train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d36e11f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13822    N\n",
       "13823    T\n",
       "13824    N\n",
       "13825    N\n",
       "13826    N\n",
       "13827    N\n",
       "13828    N\n",
       "13829    N\n",
       "13830    N\n",
       "13831    N\n",
       "Name: Label, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = df['Label']\n",
    "y.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "554afccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_0</th>\n",
       "      <th>F_1</th>\n",
       "      <th>F_2</th>\n",
       "      <th>F_3</th>\n",
       "      <th>F_4</th>\n",
       "      <th>F_5</th>\n",
       "      <th>F_6</th>\n",
       "      <th>F_7</th>\n",
       "      <th>F_8</th>\n",
       "      <th>F_9</th>\n",
       "      <th>...</th>\n",
       "      <th>F_990</th>\n",
       "      <th>F_991</th>\n",
       "      <th>F_992</th>\n",
       "      <th>F_993</th>\n",
       "      <th>F_994</th>\n",
       "      <th>F_995</th>\n",
       "      <th>F_996</th>\n",
       "      <th>F_997</th>\n",
       "      <th>F_998</th>\n",
       "      <th>F_999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10690.636719</td>\n",
       "      <td>-25213.765625</td>\n",
       "      <td>29258.396484</td>\n",
       "      <td>22853.923828</td>\n",
       "      <td>-22368.410156</td>\n",
       "      <td>-11693.577148</td>\n",
       "      <td>8507.174805</td>\n",
       "      <td>-2724.493896</td>\n",
       "      <td>-37924.949219</td>\n",
       "      <td>11573.355469</td>\n",
       "      <td>...</td>\n",
       "      <td>34881.000000</td>\n",
       "      <td>-11942.504883</td>\n",
       "      <td>10494.958008</td>\n",
       "      <td>-15776.727539</td>\n",
       "      <td>30764.744141</td>\n",
       "      <td>18928.335938</td>\n",
       "      <td>-13308.816406</td>\n",
       "      <td>-17215.457031</td>\n",
       "      <td>-10167.539062</td>\n",
       "      <td>20104.916016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-7629.322754</td>\n",
       "      <td>-18402.431641</td>\n",
       "      <td>21075.640625</td>\n",
       "      <td>17044.130859</td>\n",
       "      <td>-17074.062500</td>\n",
       "      <td>-8875.350586</td>\n",
       "      <td>6207.130371</td>\n",
       "      <td>-2534.134033</td>\n",
       "      <td>-28035.839844</td>\n",
       "      <td>8740.409180</td>\n",
       "      <td>...</td>\n",
       "      <td>25396.242188</td>\n",
       "      <td>-8040.164062</td>\n",
       "      <td>7526.416504</td>\n",
       "      <td>-11134.735352</td>\n",
       "      <td>21891.035156</td>\n",
       "      <td>13781.102539</td>\n",
       "      <td>-9286.528320</td>\n",
       "      <td>-12237.918945</td>\n",
       "      <td>-7031.791992</td>\n",
       "      <td>14757.584961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7409.713867</td>\n",
       "      <td>-17593.281250</td>\n",
       "      <td>19657.062500</td>\n",
       "      <td>16256.388672</td>\n",
       "      <td>-16373.372070</td>\n",
       "      <td>-8285.156250</td>\n",
       "      <td>5567.615234</td>\n",
       "      <td>-2038.848877</td>\n",
       "      <td>-26340.152344</td>\n",
       "      <td>7972.287598</td>\n",
       "      <td>...</td>\n",
       "      <td>23134.189453</td>\n",
       "      <td>-7232.945801</td>\n",
       "      <td>7283.832031</td>\n",
       "      <td>-10198.464844</td>\n",
       "      <td>20487.828125</td>\n",
       "      <td>12480.434570</td>\n",
       "      <td>-8593.717773</td>\n",
       "      <td>-11392.190430</td>\n",
       "      <td>-6298.755371</td>\n",
       "      <td>13492.181641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9487.986328</td>\n",
       "      <td>-21533.810547</td>\n",
       "      <td>24994.900391</td>\n",
       "      <td>19448.421875</td>\n",
       "      <td>-19460.894531</td>\n",
       "      <td>-10532.538086</td>\n",
       "      <td>7491.643066</td>\n",
       "      <td>-2692.489014</td>\n",
       "      <td>-32500.560547</td>\n",
       "      <td>10386.190430</td>\n",
       "      <td>...</td>\n",
       "      <td>29641.876953</td>\n",
       "      <td>-9823.654297</td>\n",
       "      <td>8988.515625</td>\n",
       "      <td>-13260.978516</td>\n",
       "      <td>26138.876953</td>\n",
       "      <td>16142.136719</td>\n",
       "      <td>-11179.166016</td>\n",
       "      <td>-14604.679688</td>\n",
       "      <td>-8382.214844</td>\n",
       "      <td>17354.947266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-11941.234375</td>\n",
       "      <td>-29637.691406</td>\n",
       "      <td>35033.589844</td>\n",
       "      <td>27598.150391</td>\n",
       "      <td>-26310.652344</td>\n",
       "      <td>-13651.644531</td>\n",
       "      <td>10284.687500</td>\n",
       "      <td>-3895.448486</td>\n",
       "      <td>-44680.093750</td>\n",
       "      <td>13856.203125</td>\n",
       "      <td>...</td>\n",
       "      <td>41469.593750</td>\n",
       "      <td>-14147.382812</td>\n",
       "      <td>12032.883789</td>\n",
       "      <td>-18577.267578</td>\n",
       "      <td>35908.304688</td>\n",
       "      <td>22637.023438</td>\n",
       "      <td>-15558.220703</td>\n",
       "      <td>-20085.800781</td>\n",
       "      <td>-11846.132812</td>\n",
       "      <td>23801.306641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            F_0           F_1           F_2           F_3           F_4  \\\n",
       "0 -10690.636719 -25213.765625  29258.396484  22853.923828 -22368.410156   \n",
       "1  -7629.322754 -18402.431641  21075.640625  17044.130859 -17074.062500   \n",
       "2  -7409.713867 -17593.281250  19657.062500  16256.388672 -16373.372070   \n",
       "3  -9487.986328 -21533.810547  24994.900391  19448.421875 -19460.894531   \n",
       "4 -11941.234375 -29637.691406  35033.589844  27598.150391 -26310.652344   \n",
       "\n",
       "            F_5           F_6          F_7           F_8           F_9  ...  \\\n",
       "0 -11693.577148   8507.174805 -2724.493896 -37924.949219  11573.355469  ...   \n",
       "1  -8875.350586   6207.130371 -2534.134033 -28035.839844   8740.409180  ...   \n",
       "2  -8285.156250   5567.615234 -2038.848877 -26340.152344   7972.287598  ...   \n",
       "3 -10532.538086   7491.643066 -2692.489014 -32500.560547  10386.190430  ...   \n",
       "4 -13651.644531  10284.687500 -3895.448486 -44680.093750  13856.203125  ...   \n",
       "\n",
       "          F_990         F_991         F_992         F_993         F_994  \\\n",
       "0  34881.000000 -11942.504883  10494.958008 -15776.727539  30764.744141   \n",
       "1  25396.242188  -8040.164062   7526.416504 -11134.735352  21891.035156   \n",
       "2  23134.189453  -7232.945801   7283.832031 -10198.464844  20487.828125   \n",
       "3  29641.876953  -9823.654297   8988.515625 -13260.978516  26138.876953   \n",
       "4  41469.593750 -14147.382812  12032.883789 -18577.267578  35908.304688   \n",
       "\n",
       "          F_995         F_996         F_997         F_998         F_999  \n",
       "0  18928.335938 -13308.816406 -17215.457031 -10167.539062  20104.916016  \n",
       "1  13781.102539  -9286.528320 -12237.918945  -7031.791992  14757.584961  \n",
       "2  12480.434570  -8593.717773 -11392.190430  -6298.755371  13492.181641  \n",
       "3  16142.136719 -11179.166016 -14604.679688  -8382.214844  17354.947266  \n",
       "4  22637.023438 -15558.220703 -20085.800781 -11846.132812  23801.306641  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['Label'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc980d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c5ad4_row9_col1, #T_c5ad4_row16_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c5ad4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c5ad4_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_c5ad4_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c5ad4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c5ad4_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_c5ad4_row0_col1\" class=\"data row0 col1\" >100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5ad4_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c5ad4_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_c5ad4_row1_col1\" class=\"data row1 col1\" >Label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5ad4_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c5ad4_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_c5ad4_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5ad4_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c5ad4_row3_col0\" class=\"data row3 col0\" >Target mapping</td>\n",
       "      <td id=\"T_c5ad4_row3_col1\" class=\"data row3 col1\" >N: 0, T: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5ad4_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c5ad4_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_c5ad4_row4_col1\" class=\"data row4 col1\" >(13832, 1001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5ad4_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c5ad4_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_c5ad4_row5_col1\" class=\"data row5 col1\" >(13832, 1001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5ad4_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_c5ad4_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_c5ad4_row6_col1\" class=\"data row6 col1\" >(9682, 1001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5ad4_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_c5ad4_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_c5ad4_row7_col1\" class=\"data row7 col1\" >(4150, 1001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5ad4_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_c5ad4_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_c5ad4_row8_col1\" class=\"data row8 col1\" >1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5ad4_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_c5ad4_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n",
       "      <td id=\"T_c5ad4_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5ad4_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_c5ad4_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n",
       "      <td id=\"T_c5ad4_row10_col1\" class=\"data row10 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5ad4_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_c5ad4_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_c5ad4_row11_col1\" class=\"data row11 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5ad4_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_c5ad4_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_c5ad4_row12_col1\" class=\"data row12 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5ad4_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_c5ad4_row13_col0\" class=\"data row13 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_c5ad4_row13_col1\" class=\"data row13 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5ad4_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_c5ad4_row14_col0\" class=\"data row14 col0\" >Fold Number</td>\n",
       "      <td id=\"T_c5ad4_row14_col1\" class=\"data row14 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5ad4_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_c5ad4_row15_col0\" class=\"data row15 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_c5ad4_row15_col1\" class=\"data row15 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5ad4_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_c5ad4_row16_col0\" class=\"data row16 col0\" >Use GPU</td>\n",
       "      <td id=\"T_c5ad4_row16_col1\" class=\"data row16 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5ad4_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_c5ad4_row17_col0\" class=\"data row17 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_c5ad4_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5ad4_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_c5ad4_row18_col0\" class=\"data row18 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_c5ad4_row18_col1\" class=\"data row18 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c5ad4_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_c5ad4_row19_col0\" class=\"data row19 col0\" >USI</td>\n",
       "      <td id=\"T_c5ad4_row19_col1\" class=\"data row19 col1\" >f7cb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23c216a6160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = setup(data = df ,\n",
    "                   target = y ,\n",
    "                   session_id = 100 ,\n",
    "                   n_jobs=-1,\n",
    "                   use_gpu=True,\n",
    "                   fold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f7675a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d93ea th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d93ea_row0_col0, #T_d93ea_row0_col3, #T_d93ea_row0_col4, #T_d93ea_row1_col0, #T_d93ea_row1_col1, #T_d93ea_row1_col2, #T_d93ea_row1_col4, #T_d93ea_row1_col5, #T_d93ea_row1_col6, #T_d93ea_row1_col7, #T_d93ea_row2_col0, #T_d93ea_row2_col1, #T_d93ea_row2_col2, #T_d93ea_row2_col3, #T_d93ea_row2_col4, #T_d93ea_row2_col5, #T_d93ea_row2_col6, #T_d93ea_row2_col7, #T_d93ea_row3_col0, #T_d93ea_row3_col1, #T_d93ea_row3_col2, #T_d93ea_row3_col3, #T_d93ea_row3_col5, #T_d93ea_row3_col6, #T_d93ea_row3_col7, #T_d93ea_row4_col0, #T_d93ea_row4_col1, #T_d93ea_row4_col2, #T_d93ea_row4_col3, #T_d93ea_row4_col4, #T_d93ea_row4_col5, #T_d93ea_row4_col6, #T_d93ea_row4_col7, #T_d93ea_row5_col0, #T_d93ea_row5_col1, #T_d93ea_row5_col2, #T_d93ea_row5_col3, #T_d93ea_row5_col4, #T_d93ea_row5_col5, #T_d93ea_row5_col6, #T_d93ea_row5_col7, #T_d93ea_row6_col0, #T_d93ea_row6_col1, #T_d93ea_row6_col2, #T_d93ea_row6_col3, #T_d93ea_row6_col4, #T_d93ea_row6_col5, #T_d93ea_row6_col6, #T_d93ea_row6_col7, #T_d93ea_row7_col0, #T_d93ea_row7_col1, #T_d93ea_row7_col2, #T_d93ea_row7_col3, #T_d93ea_row7_col4, #T_d93ea_row7_col5, #T_d93ea_row7_col6, #T_d93ea_row7_col7, #T_d93ea_row8_col0, #T_d93ea_row8_col1, #T_d93ea_row8_col2, #T_d93ea_row8_col3, #T_d93ea_row8_col4, #T_d93ea_row8_col5, #T_d93ea_row8_col6, #T_d93ea_row8_col7, #T_d93ea_row9_col0, #T_d93ea_row9_col1, #T_d93ea_row9_col2, #T_d93ea_row9_col3, #T_d93ea_row9_col4, #T_d93ea_row9_col5, #T_d93ea_row9_col6, #T_d93ea_row9_col7, #T_d93ea_row10_col0, #T_d93ea_row10_col1, #T_d93ea_row10_col2, #T_d93ea_row10_col3, #T_d93ea_row10_col4, #T_d93ea_row10_col5, #T_d93ea_row10_col6, #T_d93ea_row10_col7, #T_d93ea_row11_col0, #T_d93ea_row11_col1, #T_d93ea_row11_col2, #T_d93ea_row11_col3, #T_d93ea_row11_col4, #T_d93ea_row11_col5, #T_d93ea_row11_col6, #T_d93ea_row11_col7, #T_d93ea_row12_col0, #T_d93ea_row12_col1, #T_d93ea_row12_col2, #T_d93ea_row12_col3, #T_d93ea_row12_col4, #T_d93ea_row12_col5, #T_d93ea_row12_col6, #T_d93ea_row12_col7, #T_d93ea_row13_col0, #T_d93ea_row13_col1, #T_d93ea_row13_col2, #T_d93ea_row13_col3, #T_d93ea_row13_col4, #T_d93ea_row13_col5, #T_d93ea_row13_col6, #T_d93ea_row13_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d93ea_row0_col1, #T_d93ea_row0_col2, #T_d93ea_row0_col5, #T_d93ea_row0_col6, #T_d93ea_row0_col7, #T_d93ea_row1_col3, #T_d93ea_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_d93ea_row0_col8, #T_d93ea_row1_col8, #T_d93ea_row3_col8, #T_d93ea_row4_col8, #T_d93ea_row5_col8, #T_d93ea_row6_col8, #T_d93ea_row7_col8, #T_d93ea_row8_col8, #T_d93ea_row9_col8, #T_d93ea_row10_col8, #T_d93ea_row11_col8, #T_d93ea_row12_col8, #T_d93ea_row13_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_d93ea_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d93ea\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d93ea_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_d93ea_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_d93ea_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_d93ea_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_d93ea_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_d93ea_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_d93ea_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_d93ea_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_d93ea_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d93ea_level0_row0\" class=\"row_heading level0 row0\" >lightgbm</th>\n",
       "      <td id=\"T_d93ea_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_d93ea_row0_col1\" class=\"data row0 col1\" >0.9663</td>\n",
       "      <td id=\"T_d93ea_row0_col2\" class=\"data row0 col2\" >0.9767</td>\n",
       "      <td id=\"T_d93ea_row0_col3\" class=\"data row0 col3\" >0.6685</td>\n",
       "      <td id=\"T_d93ea_row0_col4\" class=\"data row0 col4\" >0.9508</td>\n",
       "      <td id=\"T_d93ea_row0_col5\" class=\"data row0 col5\" >0.7849</td>\n",
       "      <td id=\"T_d93ea_row0_col6\" class=\"data row0 col6\" >0.7672</td>\n",
       "      <td id=\"T_d93ea_row0_col7\" class=\"data row0 col7\" >0.7814</td>\n",
       "      <td id=\"T_d93ea_row0_col8\" class=\"data row0 col8\" >0.5640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93ea_level0_row1\" class=\"row_heading level0 row1\" >lda</th>\n",
       "      <td id=\"T_d93ea_row1_col0\" class=\"data row1 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_d93ea_row1_col1\" class=\"data row1 col1\" >0.9576</td>\n",
       "      <td id=\"T_d93ea_row1_col2\" class=\"data row1 col2\" >0.9507</td>\n",
       "      <td id=\"T_d93ea_row1_col3\" class=\"data row1 col3\" >0.6753</td>\n",
       "      <td id=\"T_d93ea_row1_col4\" class=\"data row1 col4\" >0.8315</td>\n",
       "      <td id=\"T_d93ea_row1_col5\" class=\"data row1 col5\" >0.7452</td>\n",
       "      <td id=\"T_d93ea_row1_col6\" class=\"data row1 col6\" >0.7223</td>\n",
       "      <td id=\"T_d93ea_row1_col7\" class=\"data row1 col7\" >0.7270</td>\n",
       "      <td id=\"T_d93ea_row1_col8\" class=\"data row1 col8\" >0.4760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93ea_level0_row2\" class=\"row_heading level0 row2\" >ridge</th>\n",
       "      <td id=\"T_d93ea_row2_col0\" class=\"data row2 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_d93ea_row2_col1\" class=\"data row2 col1\" >0.9541</td>\n",
       "      <td id=\"T_d93ea_row2_col2\" class=\"data row2 col2\" >0.0000</td>\n",
       "      <td id=\"T_d93ea_row2_col3\" class=\"data row2 col3\" >0.5640</td>\n",
       "      <td id=\"T_d93ea_row2_col4\" class=\"data row2 col4\" >0.8999</td>\n",
       "      <td id=\"T_d93ea_row2_col5\" class=\"data row2 col5\" >0.6933</td>\n",
       "      <td id=\"T_d93ea_row2_col6\" class=\"data row2 col6\" >0.6699</td>\n",
       "      <td id=\"T_d93ea_row2_col7\" class=\"data row2 col7\" >0.6914</td>\n",
       "      <td id=\"T_d93ea_row2_col8\" class=\"data row2 col8\" >0.3820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93ea_level0_row3\" class=\"row_heading level0 row3\" >rf</th>\n",
       "      <td id=\"T_d93ea_row3_col0\" class=\"data row3 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_d93ea_row3_col1\" class=\"data row3 col1\" >0.9498</td>\n",
       "      <td id=\"T_d93ea_row3_col2\" class=\"data row3 col2\" >0.9579</td>\n",
       "      <td id=\"T_d93ea_row3_col3\" class=\"data row3 col3\" >0.4719</td>\n",
       "      <td id=\"T_d93ea_row3_col4\" class=\"data row3 col4\" >0.9631</td>\n",
       "      <td id=\"T_d93ea_row3_col5\" class=\"data row3 col5\" >0.6331</td>\n",
       "      <td id=\"T_d93ea_row3_col6\" class=\"data row3 col6\" >0.6096</td>\n",
       "      <td id=\"T_d93ea_row3_col7\" class=\"data row3 col7\" >0.6547</td>\n",
       "      <td id=\"T_d93ea_row3_col8\" class=\"data row3 col8\" >0.6280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93ea_level0_row4\" class=\"row_heading level0 row4\" >et</th>\n",
       "      <td id=\"T_d93ea_row4_col0\" class=\"data row4 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_d93ea_row4_col1\" class=\"data row4 col1\" >0.9493</td>\n",
       "      <td id=\"T_d93ea_row4_col2\" class=\"data row4 col2\" >0.9533</td>\n",
       "      <td id=\"T_d93ea_row4_col3\" class=\"data row4 col3\" >0.4708</td>\n",
       "      <td id=\"T_d93ea_row4_col4\" class=\"data row4 col4\" >0.9549</td>\n",
       "      <td id=\"T_d93ea_row4_col5\" class=\"data row4 col5\" >0.6297</td>\n",
       "      <td id=\"T_d93ea_row4_col6\" class=\"data row4 col6\" >0.6059</td>\n",
       "      <td id=\"T_d93ea_row4_col7\" class=\"data row4 col7\" >0.6503</td>\n",
       "      <td id=\"T_d93ea_row4_col8\" class=\"data row4 col8\" >0.6480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93ea_level0_row5\" class=\"row_heading level0 row5\" >gbc</th>\n",
       "      <td id=\"T_d93ea_row5_col0\" class=\"data row5 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_d93ea_row5_col1\" class=\"data row5 col1\" >0.9396</td>\n",
       "      <td id=\"T_d93ea_row5_col2\" class=\"data row5 col2\" >0.9343</td>\n",
       "      <td id=\"T_d93ea_row5_col3\" class=\"data row5 col3\" >0.3831</td>\n",
       "      <td id=\"T_d93ea_row5_col4\" class=\"data row5 col4\" >0.9066</td>\n",
       "      <td id=\"T_d93ea_row5_col5\" class=\"data row5 col5\" >0.5370</td>\n",
       "      <td id=\"T_d93ea_row5_col6\" class=\"data row5 col6\" >0.5104</td>\n",
       "      <td id=\"T_d93ea_row5_col7\" class=\"data row5 col7\" >0.5658</td>\n",
       "      <td id=\"T_d93ea_row5_col8\" class=\"data row5 col8\" >0.5380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93ea_level0_row6\" class=\"row_heading level0 row6\" >lr</th>\n",
       "      <td id=\"T_d93ea_row6_col0\" class=\"data row6 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_d93ea_row6_col1\" class=\"data row6 col1\" >0.9393</td>\n",
       "      <td id=\"T_d93ea_row6_col2\" class=\"data row6 col2\" >0.8988</td>\n",
       "      <td id=\"T_d93ea_row6_col3\" class=\"data row6 col3\" >0.4517</td>\n",
       "      <td id=\"T_d93ea_row6_col4\" class=\"data row6 col4\" >0.8033</td>\n",
       "      <td id=\"T_d93ea_row6_col5\" class=\"data row6 col5\" >0.5768</td>\n",
       "      <td id=\"T_d93ea_row6_col6\" class=\"data row6 col6\" >0.5469</td>\n",
       "      <td id=\"T_d93ea_row6_col7\" class=\"data row6 col7\" >0.5740</td>\n",
       "      <td id=\"T_d93ea_row6_col8\" class=\"data row6 col8\" >0.4800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93ea_level0_row7\" class=\"row_heading level0 row7\" >dt</th>\n",
       "      <td id=\"T_d93ea_row7_col0\" class=\"data row7 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_d93ea_row7_col1\" class=\"data row7 col1\" >0.9318</td>\n",
       "      <td id=\"T_d93ea_row7_col2\" class=\"data row7 col2\" >0.7963</td>\n",
       "      <td id=\"T_d93ea_row7_col3\" class=\"data row7 col3\" >0.6303</td>\n",
       "      <td id=\"T_d93ea_row7_col4\" class=\"data row7 col4\" >0.6290</td>\n",
       "      <td id=\"T_d93ea_row7_col5\" class=\"data row7 col5\" >0.6294</td>\n",
       "      <td id=\"T_d93ea_row7_col6\" class=\"data row7 col6\" >0.5919</td>\n",
       "      <td id=\"T_d93ea_row7_col7\" class=\"data row7 col7\" >0.5920</td>\n",
       "      <td id=\"T_d93ea_row7_col8\" class=\"data row7 col8\" >0.4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93ea_level0_row8\" class=\"row_heading level0 row8\" >knn</th>\n",
       "      <td id=\"T_d93ea_row8_col0\" class=\"data row8 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_d93ea_row8_col1\" class=\"data row8 col1\" >0.9279</td>\n",
       "      <td id=\"T_d93ea_row8_col2\" class=\"data row8 col2\" >0.8268</td>\n",
       "      <td id=\"T_d93ea_row8_col3\" class=\"data row8 col3\" >0.3135</td>\n",
       "      <td id=\"T_d93ea_row8_col4\" class=\"data row8 col4\" >0.7639</td>\n",
       "      <td id=\"T_d93ea_row8_col5\" class=\"data row8 col5\" >0.4442</td>\n",
       "      <td id=\"T_d93ea_row8_col6\" class=\"data row8 col6\" >0.4127</td>\n",
       "      <td id=\"T_d93ea_row8_col7\" class=\"data row8 col7\" >0.4602</td>\n",
       "      <td id=\"T_d93ea_row8_col8\" class=\"data row8 col8\" >1.1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93ea_level0_row9\" class=\"row_heading level0 row9\" >ada</th>\n",
       "      <td id=\"T_d93ea_row9_col0\" class=\"data row9 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_d93ea_row9_col1\" class=\"data row9 col1\" >0.9232</td>\n",
       "      <td id=\"T_d93ea_row9_col2\" class=\"data row9 col2\" >0.8834</td>\n",
       "      <td id=\"T_d93ea_row9_col3\" class=\"data row9 col3\" >0.2584</td>\n",
       "      <td id=\"T_d93ea_row9_col4\" class=\"data row9 col4\" >0.7303</td>\n",
       "      <td id=\"T_d93ea_row9_col5\" class=\"data row9 col5\" >0.3805</td>\n",
       "      <td id=\"T_d93ea_row9_col6\" class=\"data row9 col6\" >0.3496</td>\n",
       "      <td id=\"T_d93ea_row9_col7\" class=\"data row9 col7\" >0.4044</td>\n",
       "      <td id=\"T_d93ea_row9_col8\" class=\"data row9 col8\" >0.7100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93ea_level0_row10\" class=\"row_heading level0 row10\" >qda</th>\n",
       "      <td id=\"T_d93ea_row10_col0\" class=\"data row10 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_d93ea_row10_col1\" class=\"data row10 col1\" >0.9081</td>\n",
       "      <td id=\"T_d93ea_row10_col2\" class=\"data row10 col2\" >0.5000</td>\n",
       "      <td id=\"T_d93ea_row10_col3\" class=\"data row10 col3\" >0.0000</td>\n",
       "      <td id=\"T_d93ea_row10_col4\" class=\"data row10 col4\" >0.0000</td>\n",
       "      <td id=\"T_d93ea_row10_col5\" class=\"data row10 col5\" >0.0000</td>\n",
       "      <td id=\"T_d93ea_row10_col6\" class=\"data row10 col6\" >0.0000</td>\n",
       "      <td id=\"T_d93ea_row10_col7\" class=\"data row10 col7\" >0.0000</td>\n",
       "      <td id=\"T_d93ea_row10_col8\" class=\"data row10 col8\" >0.5380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93ea_level0_row11\" class=\"row_heading level0 row11\" >dummy</th>\n",
       "      <td id=\"T_d93ea_row11_col0\" class=\"data row11 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_d93ea_row11_col1\" class=\"data row11 col1\" >0.9081</td>\n",
       "      <td id=\"T_d93ea_row11_col2\" class=\"data row11 col2\" >0.5000</td>\n",
       "      <td id=\"T_d93ea_row11_col3\" class=\"data row11 col3\" >0.0000</td>\n",
       "      <td id=\"T_d93ea_row11_col4\" class=\"data row11 col4\" >0.0000</td>\n",
       "      <td id=\"T_d93ea_row11_col5\" class=\"data row11 col5\" >0.0000</td>\n",
       "      <td id=\"T_d93ea_row11_col6\" class=\"data row11 col6\" >0.0000</td>\n",
       "      <td id=\"T_d93ea_row11_col7\" class=\"data row11 col7\" >0.0000</td>\n",
       "      <td id=\"T_d93ea_row11_col8\" class=\"data row11 col8\" >0.4540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93ea_level0_row12\" class=\"row_heading level0 row12\" >svm</th>\n",
       "      <td id=\"T_d93ea_row12_col0\" class=\"data row12 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_d93ea_row12_col1\" class=\"data row12 col1\" >0.8900</td>\n",
       "      <td id=\"T_d93ea_row12_col2\" class=\"data row12 col2\" >0.0000</td>\n",
       "      <td id=\"T_d93ea_row12_col3\" class=\"data row12 col3\" >0.1236</td>\n",
       "      <td id=\"T_d93ea_row12_col4\" class=\"data row12 col4\" >0.1501</td>\n",
       "      <td id=\"T_d93ea_row12_col5\" class=\"data row12 col5\" >0.1114</td>\n",
       "      <td id=\"T_d93ea_row12_col6\" class=\"data row12 col6\" >0.0857</td>\n",
       "      <td id=\"T_d93ea_row12_col7\" class=\"data row12 col7\" >0.0971</td>\n",
       "      <td id=\"T_d93ea_row12_col8\" class=\"data row12 col8\" >0.3860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93ea_level0_row13\" class=\"row_heading level0 row13\" >nb</th>\n",
       "      <td id=\"T_d93ea_row13_col0\" class=\"data row13 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_d93ea_row13_col1\" class=\"data row13 col1\" >0.4627</td>\n",
       "      <td id=\"T_d93ea_row13_col2\" class=\"data row13 col2\" >0.5414</td>\n",
       "      <td id=\"T_d93ea_row13_col3\" class=\"data row13 col3\" >0.5348</td>\n",
       "      <td id=\"T_d93ea_row13_col4\" class=\"data row13 col4\" >0.0905</td>\n",
       "      <td id=\"T_d93ea_row13_col5\" class=\"data row13 col5\" >0.1547</td>\n",
       "      <td id=\"T_d93ea_row13_col6\" class=\"data row13 col6\" >-0.0029</td>\n",
       "      <td id=\"T_d93ea_row13_col7\" class=\"data row13 col7\" >-0.0057</td>\n",
       "      <td id=\"T_d93ea_row13_col8\" class=\"data row13 col8\" >0.6240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23d53734310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_5 = compare_models(n_select = 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839b2052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822ac587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
