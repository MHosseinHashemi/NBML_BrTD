{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f2a56a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import cv2\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import *\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e919ce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit GPU Memmory growth:\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69d52a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # A function to annotate and extract labels\n",
    "# image_size = 540\n",
    "\n",
    "# def load_data(image_dir, annotation_dir):\n",
    "# #     images = []\n",
    "# #     labels = []\n",
    "#     data = []\n",
    "\n",
    "#     for image_path in tqdm(os.listdir(image_dir)):\n",
    "#         if image_path.endswith('.jpg'):\n",
    "#             image = cv2.imread(os.path.join(image_dir, image_path), cv2.IMREAD_GRAYSCALE)\n",
    "#             # Normalize to [0, 1]\n",
    "#             image = cv2.resize(image,(image_size, image_size))\n",
    "#             image = image.astype('float32') / 255.0  \n",
    "# #             images.append(image)\n",
    "\n",
    "#             annotation_path = os.path.join(annotation_dir, os.path.splitext(image_path)[0] + '.json')\n",
    "#             if os.path.exists(annotation_path):\n",
    "#                 with open(annotation_path, 'r') as f:\n",
    "#                     annotation = json.load(f)\n",
    "#                 # Extract bounding box coordinates and class label from the annotation\n",
    "#                 bbox = annotation['shapes'][0]['points']\n",
    "#                 label = 1  # Tumor class label\n",
    "#             else:\n",
    "#                 bbox = []\n",
    "#                 # Normal class label\n",
    "#                 label = 0  \n",
    "# #             labels.append((bbox, label))\n",
    "#             data.append({'image':image, 'bbox':bbox, 'label':label})\n",
    "            \n",
    "\n",
    "#     return data\n",
    "# #     return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9086b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewrite in order to prevent any possible errors\n",
    "image_size = 540\n",
    "\n",
    "def load_data(image_dir, annotation_dir):\n",
    "    data = []\n",
    "\n",
    "    for image_path in tqdm(os.listdir(image_dir)):\n",
    "        if image_path.endswith('.jpg'):\n",
    "            image = cv2.imread(os.path.join(image_dir, image_path), cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (540, 540))\n",
    "            image = image.astype('float32') / 255.0\n",
    "\n",
    "            annotation_path = os.path.join(annotation_dir, os.path.splitext(image_path)[0] + '.json')\n",
    "            if os.path.exists(annotation_path):\n",
    "                with open(annotation_path, 'r') as f:\n",
    "                    annotation = json.load(f)\n",
    "                \n",
    "                bbox = annotation['shapes'][0]['points']\n",
    "                label = 1  \n",
    "                \n",
    "            else:\n",
    "                bbox = [[-1, -1], [-1, -1]]\n",
    "                label = 0\n",
    "\n",
    "            data.append({'image': image, 'bbox': bbox, 'label': label})\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff6b8b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 13832/13832 [00:44<00:00, 311.07it/s]\n"
     ]
    }
   ],
   "source": [
    "data = load_data(\"Data\\\\Train_Data\\\\Images\", \"Data\\\\Train_Data\\\\Labels\")\n",
    "# images, labels = load_data(\"Data\\\\Train_Data\\\\Images\", \"Data\\\\Train_Data\\\\Labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e75997",
   "metadata": {},
   "source": [
    "# Train Test Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57bbae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test_data_init = train_test_split(data, test_size=0.3, stratify=[d['label'] for d in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7de6e011",
   "metadata": {},
   "outputs": [],
   "source": [
    "test, val = train_test_split(test_data_init, test_size=0.5, stratify=[d['label'] for d in test_data_init])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c0ec084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9682, 2075, 2075)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test), len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00faad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#double checking the distribution of labels\n",
    "# z = 0\n",
    "# o = 1\n",
    "# for idx in range(len(val)):\n",
    "#     if val[idx]['label']==0:\n",
    "#         z+=1\n",
    "#     else:\n",
    "#         o+=1\n",
    "        \n",
    "# o = o*100/len(val) \n",
    "\n",
    "# print(f\"The percentage of ones is : {o}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c203d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels = []\n",
    "# train_images = []\n",
    "\n",
    "# for idx in tqdm(range(len(train))):\n",
    "#     temp_var_1 = train[idx]['bbox']\n",
    "#     temp_var_2 = train[idx]['label']\n",
    "    \n",
    "#     train_labels.append((temp_var_2, temp_var_1))\n",
    "#     train_images.append(train[idx]['image'])\n",
    "    \n",
    "#     del temp_var_1, temp_var_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6cc57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this instead\n",
    "train_images = np.array([d['image'] for d in train])\n",
    "train_labels_bbox = np.array([d['bbox'] for d in train])\n",
    "train_labels_class = np.array([d['label'] for d in train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9348ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_labels = []\n",
    "# test_images = []\n",
    "\n",
    "# for idx in tqdm(range(len(test))):\n",
    "#     temp_var_1 = test[idx]['bbox']\n",
    "#     temp_var_2 = test[idx]['label']\n",
    "    \n",
    "#     test_labels.append((temp_var_2, temp_var_1))\n",
    "#     test_images.append(test[idx]['image'])\n",
    "    \n",
    "#     del temp_var_1, temp_var_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a20251ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = np.array([d['image'] for d in test])\n",
    "test_labels_bbox = np.array([d['bbox'] for d in test])\n",
    "test_labels_class = np.array([d['label'] for d in test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e70d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_labels = []\n",
    "# val_images = []\n",
    "\n",
    "# for idx in tqdm(range(len(val))):\n",
    "#     temp_var_1 = val[idx]['bbox']\n",
    "#     temp_var_2 = val[idx]['label']\n",
    "    \n",
    "#     val_labels.append((temp_var_2, temp_var_1))\n",
    "#     val_images.append(val[idx]['image'])\n",
    "    \n",
    "#     del temp_var_1, temp_var_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd096faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = np.array([d['image'] for d in val])\n",
    "val_labels_bbox = np.array([d['bbox'] for d in val])\n",
    "val_labels_class = np.array([d['label'] for d in val])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff87201",
   "metadata": {},
   "source": [
    "The data succesfully distributed into 3 sections: 1.Train, 2.Test, 3.Validation and on each one of these, the first element is image array and the label element is a tuple of bouding box and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ac06495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "del data, test_data_init, train, test, val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640d7b05",
   "metadata": {},
   "source": [
    "# Beware! Error Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6bb71c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Create TensorFlow datasets for images, bboxes, and labels\"\"\"\n",
    "# train_images = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "# train_labels = tf.data.Dataset.from_tensor_slices(train_labels)\n",
    "# # Zip the datasets to create the final dataset\n",
    "# train_ds = tf.data.Dataset.zip((train_images, train_labels))\n",
    "# train_ds = train_ds.shuffle(10000)\n",
    "# train_ds = train_ds.batch(8)\n",
    "# train_ds = train_ds.prefetch(4)\n",
    "# # Clean your path\n",
    "# del train_images, train_labels\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccec888",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create TensorFlow datasets for images, bboxes, and labels\"\"\"\n",
    "# test_images = tf.data.Dataset.from_tensor_slices(test_images)\n",
    "# test_labels = tf.data.Dataset.from_tensor_slices(test_labels)\n",
    "# # Zip the datasets to create the final dataset\n",
    "# test_ds = tf.data.Dataset.zip((test_images, test_labels))\n",
    "# test_ds = test_ds.shuffle(2100)\n",
    "# test_ds = test_ds.batch(8)\n",
    "# test_ds = test_ds.prefetch(4)\n",
    "# # Clean your path\n",
    "# del test_images, test_labels\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07e935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create TensorFlow datasets for images, bboxes, and labels\"\"\"\n",
    "# val_images = tf.data.Dataset.from_tensor_slices(val_images)\n",
    "# val_labels = tf.data.Dataset.from_tensor_slices(val_labels)\n",
    "# # Zip the datasets to create the final dataset\n",
    "# val_ds = tf.data.Dataset.zip((val_images, val_labels))\n",
    "# val_ds = val_ds.shuffle(2100)\n",
    "# val_ds = val_ds.batch(8)\n",
    "# val_ds = val_ds.prefetch(4)\n",
    "# # Clean your path\n",
    "# del val_images, val_labels\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776f1a3e",
   "metadata": {},
   "source": [
    "InternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f28a9",
   "metadata": {},
   "source": [
    "# Solved !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce19e36",
   "metadata": {},
   "source": [
    "In this modified code, we define a DataGenerator class that takes in the train_images and train_labels as the training data, and a batch_size of 8. We then instantiate the generator object train_gen and pass it to the model.fit() method.\n",
    "\n",
    "The number of steps per epoch is calculated by dividing the length of the train_images by the batch_size. This value is then passed as the steps_per_epoch argument to model.fit().\n",
    "\n",
    "By using the DataGenerator class instead of creating a tf.data.Dataset, we're able to load the data in batches and avoid memory issues that could occur if we tried to load the entire dataset into memory at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0d3d7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "# class DataGenerator:\n",
    "#     def __init__(self, images, labels, batch_size):\n",
    "#         self.images, self.labels = images, labels\n",
    "#         self.batch_size = batch_size\n",
    "#         self.indices = np.arange(len(images))\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return int(np.ceil(len(self.images) / float(self.batch_size)))\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "#         batch_images = [self.images[i] for i in indices]\n",
    "#         batch_labels = [self.labels[i] for i in indices]\n",
    "# #         batch_labels = [l[1] for l in batch_labels]\n",
    "# #         batch_boxes = [b[0] for b in batch_labels]\n",
    "        \n",
    "        \n",
    "#         return np.array(batch_images), np.array(batch_labels)\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, images, labels_bbox, labels_class, batch_size):\n",
    "        self.images = images\n",
    "        self.labels_bbox = labels_bbox\n",
    "        self.labels_class = labels_class\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(len(images))\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.images) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_images = self.images[indices]\n",
    "        batch_labels_bbox = self.labels_bbox[indices]\n",
    "        batch_labels_class = self.labels_class[indices]\n",
    "        \n",
    "        # A bit of headache\n",
    "        batch_images = np.expand_dims(batch_images, axis=-1)\n",
    "#         # Another headache\n",
    "#         batch_labels_bbox = np.expand_dims(batch_labels_bbox, axis=-1)\n",
    "#         batch_labels_class = np.expand_dims(batch_labels_class, axis=-1)\n",
    "    \n",
    "        return batch_images, {'bb_output': batch_labels_bbox, 'label_output': batch_labels_class}\n",
    "    \n",
    "\n",
    "train_gen = DataGenerator(train_images, train_labels_bbox, train_labels_class, batch_size=16)\n",
    "test_gen = DataGenerator(test_images, test_labels_bbox, test_labels_class, batch_size=16)\n",
    "val_gen = DataGenerator(val_images, val_labels_bbox, val_labels_class, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd841439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_gen = DataGenerator(train_images, train_labels, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4c6702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_gen = DataGenerator(test_images, test_labels, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ecd6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_gen = DataGenerator(val_images, val_labels, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca5676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we created our generators we dont need these items\n",
    "# del train_images, train_labels, test_images, test_labels, val_images, val_labels\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc561c4",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36b3ea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(): \n",
    "    input_layer = Input(shape=(540,540,3))\n",
    "    res_net = ResNet152V2(weights='imagenet', include_top=False)(input_layer)\n",
    "\n",
    "    # Bounding box model\n",
    "    f2 = GlobalMaxPooling2D()(res_net)\n",
    "    regress1 = Dense(128, activation='relu')(f2)\n",
    "    regress2 = Dense(4, activation='sigmoid', name='bb_output')(regress1)\n",
    "    \n",
    "    # Classification Model  \n",
    "    f1 = GlobalMaxPooling2D()(res_net)\n",
    "    class1 = Dense(128, activation='relu')(f1)\n",
    "    class2 = Dense(1, activation='sigmoid', name='label_output')(class1)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=[regress2, class2])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0094fc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_detector = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26c1cc0",
   "metadata": {},
   "source": [
    "# Testing The Reliability of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef94c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras.utils as image\n",
    "# from keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "# root = \"C:\\\\Users\\\\Eurus\\\\Desktop\\\\Train_Data\\\\Tumor\\\\Tumor-img-00016-00005.jpg\"\n",
    "\n",
    "# # Read it from path\n",
    "# img = image.load_img(root, target_size=(540, 540))\n",
    "# # Prep it \n",
    "# img_data = image.img_to_array(img)\n",
    "# img_data = np.expand_dims(img_data, axis=0)\n",
    "# img_data = preprocess_input(img_data)\n",
    "# # Extract the features\n",
    "# features = tumor_detector.predict(img_data)\n",
    "# features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3805953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del features, img, img_data, root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31159f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# A custom F1-Score function\n",
    "def f1_metric(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    tp = tf.reduce_sum(y_true * y_pred)\n",
    "    fp = tf.reduce_sum(tf.clip_by_value(y_pred - y_true, 0, 1))\n",
    "    fn = tf.reduce_sum(tf.clip_by_value(y_true - y_pred, 0, 1))\n",
    "    precision = tp / (tp + fp + tf.keras.backend.epsilon())\n",
    "    recall = tp / (tp + fn + tf.keras.backend.epsilon())\n",
    "    f1 = 2 * precision * recall / (precision + recall + tf.keras.backend.epsilon())\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "597a370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def localization_loss(y_true, y_pred):\n",
    "    delta_coord = tf.reduce_sum(tf.square(y_true[:,:2] - y_pred[:,:2]))\n",
    "    \n",
    "    h_true = y_true[:,3] - y_true[:,1]\n",
    "    w_true = y_true[:,2] - y_true[:,0]\n",
    "    \n",
    "    h_pred = y_pred[:,3] - y_pred[:,1]\n",
    "    w_pred = y_pred[:,2] - y_pred[:,0]\n",
    "    \n",
    "    delta_size = tf.reduce_sum(tf.square(w_true - w_pred) + tf.square(h_true-h_pred))\n",
    "    \n",
    "    return delta_coord + delta_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fd6c3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
    "\n",
    "\n",
    "batches_per_epoches = len(train_gen)\n",
    "lr_decay = (1./0.75 -1)/batches_per_epoches\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.001, decay=lr_decay)\n",
    "classloss = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "# losses = {\n",
    "#     'bb_output': localization_loss,\n",
    "#     'label_output': BinaryCrossentropy()\n",
    "# }\n",
    "\n",
    "# metrics = {\n",
    "#     'bb_output': [Accuracy()],\n",
    "#     'label_output': [Accuracy(), Precision(), Recall()]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc24aa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tumor_detector.compile(optimizer=opt, loss=losses, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5be554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_detector.compile(\n",
    "    optimizer=opt,\n",
    "    loss={'bb_output': localization_loss, 'label_output': 'binary_crossentropy'},\n",
    "    metrics={'bb_output': Accuracy(), 'label_output': [Accuracy(), f1_metric]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4d92adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('model_weights_v1.h5', save_best_only=True, save_weights_only=True)\n",
    "lr_scheduler = ReduceLROnPlateau(factor=0.2, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d34f7002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Eurus\\Desktop\\Desktop Files\\IBNB-Paper\\GPU-Lab-2023\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Eurus\\Desktop\\Desktop Files\\IBNB-Paper\\GPU-Lab-2023\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Eurus\\Desktop\\Desktop Files\\IBNB-Paper\\GPU-Lab-2023\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Eurus\\Desktop\\Desktop Files\\IBNB-Paper\\GPU-Lab-2023\\lib\\site-packages\\keras\\engine\\training.py\", line 998, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Eurus\\Desktop\\Desktop Files\\IBNB-Paper\\GPU-Lab-2023\\lib\\site-packages\\keras\\engine\\training.py\", line 1092, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"C:\\Users\\Eurus\\Desktop\\Desktop Files\\IBNB-Paper\\GPU-Lab-2023\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 605, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"C:\\Users\\Eurus\\Desktop\\Desktop Files\\IBNB-Paper\\GPU-Lab-2023\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 77, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"C:\\Users\\Eurus\\Desktop\\Desktop Files\\IBNB-Paper\\GPU-Lab-2023\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 143, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"C:\\Users\\Eurus\\Desktop\\Desktop Files\\IBNB-Paper\\GPU-Lab-2023\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 700, in update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\Eurus\\Desktop\\Desktop Files\\IBNB-Paper\\GPU-Lab-2023\\lib\\site-packages\\keras\\metrics\\metrics.py\", line 3571, in accuracy  **\n        y_true.shape.assert_is_compatible_with(y_pred.shape)\n\n    ValueError: Shapes (None, None, None, None) and (None, 4) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtumor_detector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Desktop Files\\IBNB-Paper\\GPU-Lab-2023\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filezk8m5ywj.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Eurus\\Desktop\\Desktop Files\\IBNB-Paper\\GPU-Lab-2023\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Eurus\\Desktop\\Desktop Files\\IBNB-Paper\\GPU-Lab-2023\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Eurus\\Desktop\\Desktop Files\\IBNB-Paper\\GPU-Lab-2023\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Eurus\\Desktop\\Desktop Files\\IBNB-Paper\\GPU-Lab-2023\\lib\\site-packages\\keras\\engine\\training.py\", line 998, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Eurus\\Desktop\\Desktop Files\\IBNB-Paper\\GPU-Lab-2023\\lib\\site-packages\\keras\\engine\\training.py\", line 1092, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"C:\\Users\\Eurus\\Desktop\\Desktop Files\\IBNB-Paper\\GPU-Lab-2023\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 605, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"C:\\Users\\Eurus\\Desktop\\Desktop Files\\IBNB-Paper\\GPU-Lab-2023\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 77, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"C:\\Users\\Eurus\\Desktop\\Desktop Files\\IBNB-Paper\\GPU-Lab-2023\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 143, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"C:\\Users\\Eurus\\Desktop\\Desktop Files\\IBNB-Paper\\GPU-Lab-2023\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 700, in update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\Eurus\\Desktop\\Desktop Files\\IBNB-Paper\\GPU-Lab-2023\\lib\\site-packages\\keras\\metrics\\metrics.py\", line 3571, in accuracy  **\n        y_true.shape.assert_is_compatible_with(y_pred.shape)\n\n    ValueError: Shapes (None, None, None, None) and (None, 4) are incompatible\n"
     ]
    }
   ],
   "source": [
    "history = tumor_detector.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=50,\n",
    "    callbacks=[checkpoint, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8e448d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95b52c90",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1943087",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_metrics = tumor_detector.evaluate_generator(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16af5723",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU-Lab-2023",
   "language": "python",
   "name": "gpu-lab-2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
